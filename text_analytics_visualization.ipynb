{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adult-corps",
   "metadata": {},
   "source": [
    "## https://pythondata.com/text-analytics-visualization/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: nltk in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: regex in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from nltk) (2021.3.17)\n",
      "Requirement already satisfied: joblib in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mangoman/Desktop/tf_env/tf_gpu/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-malaysia",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "awful-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from html.parser import HTMLParser\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "stop.append(\"new\")\n",
    "stop.append(\"like\")\n",
    "stop.append(\"u\")\n",
    "stop.append(\"it\")\n",
    "stop.append(\"'s\")\n",
    "stop.append(\"n't\")\n",
    "stop.append(\"mr.\")\n",
    "stop = set(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-minister",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weekly-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html\n",
    "def tokenizer(text):\n",
    "    tokens_ = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
    "    \n",
    "    tokens = []\n",
    "    for token_by_sent in tokens_:\n",
    "        tokens += token_by_sent\n",
    "        \n",
    "    tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u'``',u\"''\", u'\\u2014', u'\\u2026', u'\\u2013'],tokens)) \n",
    "    \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wnl.lemmatize(token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "    \n",
    "    return filtered_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-roller",
   "metadata": {},
   "source": [
    "### Strip HTML text from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    \n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    \n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "    \n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tight-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(tokens, num):\n",
    "    return Counter(tokens).most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_article_df(urls):\n",
    "    articles = []\n",
    "    for index, row in urls.iterrows():\n",
    "        try:\n",
    "            data = row['text'].strip().replace(\"'\",\"\")\n",
    "            data = strip_tags(data)\n",
    "            soup = BeautifulSoup(data)\n",
    "            data = soup.get_text()\n",
    "            data = data.encode('ascii', 'ignore').decode('ascii')\n",
    "            document = tokenizer(data)\n",
    "            top_5 = get_keywords(document, 5)\n",
    "            \n",
    "            unzipped = list(zip(*top_5))\n",
    "            kw = list(unzipped[0])\n",
    "            kws = \",\".join(str(x) for x in kw)\n",
    "            articles.append((kws, row['title'], row['pubdate']))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #print data\n",
    "            #break\n",
    "            pass\n",
    "        #break\n",
    "        \n",
    "    article_df=pd.DataFrame(articles, columns =['keywords','title','pubdate'])\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-uncle",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minor-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd .read_csv('tocsv.csv')\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    data.append((row['Title'], row['Permalink'], row['Date'], row['Content']))\n",
    "data_df = pd.DataFrame(data, columns=['title','url','pubdate','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "global-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Driving Digital by Isaac Sacolick - a book review</td>\n",
       "      <td>http://ericbrown.com/driving-digital-isaac-sac...</td>\n",
       "      <td>20170906</td>\n",
       "      <td>&lt;img class=\"alignleft size-medium wp-image-975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Data and Culture go hand in hand</td>\n",
       "      <td>http://ericbrown.com/?p=9757</td>\n",
       "      <td>-11130</td>\n",
       "      <td>Last week, I spent an afternoon talking to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Data Quality - The most important data dimension?</td>\n",
       "      <td>http://ericbrown.com/data-quality-most-importa...</td>\n",
       "      <td>20170918</td>\n",
       "      <td>&lt;img class=\"size-medium wp-image-9764 alignrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Be pragmatic, not dogmatic</td>\n",
       "      <td>http://ericbrown.com/be-pragmatic-not-dogmatic...</td>\n",
       "      <td>20170928</td>\n",
       "      <td>&lt;img class=\"alignright size-medium wp-image-97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The Data Way</td>\n",
       "      <td>http://ericbrown.com/the-data-way.htm</td>\n",
       "      <td>20171003</td>\n",
       "      <td>&lt;img class=\"alignleft size-medium wp-image-977...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "143  Driving Digital by Isaac Sacolick - a book review   \n",
       "144                   Data and Culture go hand in hand   \n",
       "145  Data Quality - The most important data dimension?   \n",
       "146                         Be pragmatic, not dogmatic   \n",
       "147                                       The Data Way   \n",
       "\n",
       "                                                   url   pubdate  \\\n",
       "143  http://ericbrown.com/driving-digital-isaac-sac...  20170906   \n",
       "144                       http://ericbrown.com/?p=9757    -11130   \n",
       "145  http://ericbrown.com/data-quality-most-importa...  20170918   \n",
       "146  http://ericbrown.com/be-pragmatic-not-dogmatic...  20170928   \n",
       "147              http://ericbrown.com/the-data-way.htm  20171003   \n",
       "\n",
       "                                                  text  \n",
       "143  <img class=\"alignleft size-medium wp-image-975...  \n",
       "144  Last week, I spent an afternoon talking to the...  \n",
       "145  <img class=\"size-medium wp-image-9764 alignrig...  \n",
       "146  <img class=\"alignright size-medium wp-image-97...  \n",
       "147  <img class=\"alignleft size-medium wp-image-977...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medieval-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = build_article_df(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "difficult-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "      <td>Building a Data Culture</td>\n",
       "      <td>20141118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data,data-driven,make,company,decision</td>\n",
       "      <td>Note to Self - Don't say \"Data Driven\" Anymore</td>\n",
       "      <td>20141120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>captured,canon,titmouse,backporch,feeder</td>\n",
       "      <td>Foto Friday - Titmouse on the Feeder</td>\n",
       "      <td>20141121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobility,organization,device,mobile,access</td>\n",
       "      <td>The Cloud - Gateway to Enterprise Mobility</td>\n",
       "      <td>20141121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data,center,agile,organization,one</td>\n",
       "      <td>The Agile Data Center</td>\n",
       "      <td>20141124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     keywords  \\\n",
       "0                  data,big,culture,may,skill   \n",
       "1      data,data-driven,make,company,decision   \n",
       "2    captured,canon,titmouse,backporch,feeder   \n",
       "3  mobility,organization,device,mobile,access   \n",
       "4          data,center,agile,organization,one   \n",
       "\n",
       "                                            title   pubdate  \n",
       "0                         Building a Data Culture  20141118  \n",
       "1  Note to Self - Don't say \"Data Driven\" Anymore  20141120  \n",
       "2            Foto Friday - Titmouse on the Feeder  20141121  \n",
       "3      The Cloud - Gateway to Enterprise Mobility  20141121  \n",
       "4                           The Agile Data Center  20141124  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vital-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_array=[]\n",
    "for index, row in article_df.iterrows():\n",
    "    keywords = row['keywords'].split(',')\n",
    "    for kw in keywords:\n",
    "        keywords_array.append((kw.strip(' '), row['keywords']))\n",
    "        \n",
    "kw_df = pd.DataFrame(keywords_array).rename(columns={0:'keyword', 1:'keywords'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "processed-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big</td>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culture</td>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may</td>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skill</td>\n",
       "      <td>data,big,culture,may,skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                    keywords\n",
       "0     data  data,big,culture,may,skill\n",
       "1      big  data,big,culture,may,skill\n",
       "2  culture  data,big,culture,may,skill\n",
       "3      may  data,big,culture,may,skill\n",
       "4    skill  data,big,culture,may,skill"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "supported-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = kw_df.keywords.to_list()\n",
    "names = kw_df.keyword.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "placed-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_array =[]\n",
    "for item in document:\n",
    "    items = item.split(',')\n",
    "    document_array.append((items))\n",
    "    \n",
    "occurences = OrderedDict((name, OrderedDict((name, 0) for name in names)) for name in names)\n",
    "\n",
    "## Find the Co Occurences\n",
    "for l in document_array:\n",
    "    for i in range(len(l)):\n",
    "        for item in l[:i] + l[i+1:]:\n",
    "            occurences[l[i]][item] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moderate-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur = pd.DataFrame.from_dict(occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fuzzy-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur.to_csv('out/text_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intended-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>big</th>\n",
       "      <th>culture</th>\n",
       "      <th>may</th>\n",
       "      <th>skill</th>\n",
       "      <th>data-driven</th>\n",
       "      <th>make</th>\n",
       "      <th>company</th>\n",
       "      <th>decision</th>\n",
       "      <th>captured</th>\n",
       "      <th>...</th>\n",
       "      <th>manager</th>\n",
       "      <th>love</th>\n",
       "      <th>song</th>\n",
       "      <th>scene</th>\n",
       "      <th>isaac</th>\n",
       "      <th>quality</th>\n",
       "      <th>governance</th>\n",
       "      <th>pragmatic</th>\n",
       "      <th>dogmatic</th>\n",
       "      <th>thats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>culture</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         data  big  culture  may  skill  data-driven  make  company  decision  \\\n",
       "data        0   75        5    5      5           10    15       30         5   \n",
       "big        75    0        5    5      5            0     5       10         0   \n",
       "culture     5    5        0    5      5            0     0        5         0   \n",
       "may         5    5        5    0      5            0     0        0         0   \n",
       "skill       5    5        5    5      0            0     0        0         0   \n",
       "\n",
       "         captured  ...  manager  love  song  scene  isaac  quality  \\\n",
       "data            0  ...        0     0     0      0      0        5   \n",
       "big             5  ...        0     0     0      0      0        0   \n",
       "culture         0  ...        0     0     0      0      0        0   \n",
       "may             0  ...        0     0     0      0      0        0   \n",
       "skill           0  ...        0     0     0      0      0        0   \n",
       "\n",
       "         governance  pragmatic  dogmatic  thats  \n",
       "data              5          0         0      5  \n",
       "big               0          0         0      0  \n",
       "culture           0          0         0      0  \n",
       "may               0          0         0      0  \n",
       "skill             0          0         0      0  \n",
       "\n",
       "[5 rows x 338 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-monthly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
